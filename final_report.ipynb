{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0293956b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Project Overview:** This project aims to identify which study habits and lifestyle features most strongly influence student exam scores using a Kaggle dataset. The problem emerged from educators' and students' need to understand the drivers of academic success and to provide actionable guidance for improving learning strategies.\n",
    "\n",
    "**Problem Description & History:** As educators observed large variability in student performance, questions arose about the relative impact of factors like study time, sleep hours, attendance, and tutoring. Understanding these relationships is important to design evidence-based interventions that can boost student outcomes.\n",
    "\n",
    "### Data Acquisition and Cleaning\n",
    "\n",
    "- **Data Source:** The dataset `StudentPerformanceFactors.csv` was obtained from Kaggle, containing fields such as Study Time, Sleep Hours, Attendance, Previous Scores, Tutoring Sessions, and Motivation Level.\n",
    "- **Cleaning Steps Summary:**\n",
    "  - Removed records with missing exam scores.\n",
    "  - Filtered exam scores to make sure none exceeded 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3271c",
   "metadata": {},
   "source": [
    "### Report Outline & Assumptions\n",
    "\n",
    "**Outline of the Report:**\n",
    "1. **Introduction** – Overview, problem statement, data source, and cleaning summary.\n",
    "2. **Exploratory Data Analysis** – Descriptive statistics, distributions, and initial correlations.\n",
    "3. **Feature Correlation Analysis** – Correlation matrix, feature selection, and statistical significance tests.\n",
    "4. **Modeling & Validation** – Building regression models to predict exam scores and evaluating performance.\n",
    "5. **Discussion & Insights** – Interpretation of results, key findings, and practical recommendations.\n",
    "6. **Conclusion** – Summary of findings, limitations, and suggestions for future work.\n",
    "\n",
    "**Key Assumptions:**\n",
    "- Relationships between features and exam scores are assumed to be linear for initial correlation analysis.\n",
    "- Imputation and outlier removal do not introduce significant bias.\n",
    "- The dataset is representative of the wider student population.\n",
    "\n",
    "### Approach Summary\n",
    "\n",
    "Our approach consists of:\n",
    "1. Cleaning and preprocessing the data as described above.\n",
    "2. Conducting exploratory analysis to visualize feature distributions.\n",
    "3. Computing correlation coefficients to identify the most impactful features.\n",
    "4. Validating findings with regression models and cross-validation.\n",
    "5. Deriving actionable insights to improve student learning strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c184bf",
   "metadata": {},
   "source": [
    "## Descriptive Analysis\n",
    "\n",
    "In this section, we load the cleaned dataset, perform descriptive analysis using pivot tables and clustering, and visualize key patterns to extract insights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e11030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# Quick overview\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b24bb",
   "metadata": {},
   "source": [
    "## Cluster Interpretation\n",
    "\n",
    "- **Cluster 1** has the highest average exam score (68.8) and the highest attendance (91%), despite only moderate previous scores (65).  \n",
    "- **Cluster 2** boasts the top previous scores (89) but lower attendance (79%) and a slightly lower exam score (67.8).  \n",
    "- **Cluster 0** shows the lowest attendance (70%) and exam score (64.8), even though study hours and physical activity are similar across groups.  \n",
    "\n",
    "**Key takeaway:**  \n",
    "Among these features, **attendance** stands out as the strongest differentiator of exam performance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4697bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1) read the cleaned file\n",
    "df = pd.read_csv(\"cleaned_dataset.csv\")\n",
    "\n",
    "# 2) numeric columns only\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# 3) target vs‑ features\n",
    "target_col  = \"Exam_Score\" if \"Exam_Score\" in numeric_cols else numeric_cols[-1]\n",
    "feature_cols = [c for c in numeric_cols if c != target_col]\n",
    "\n",
    "# 4) feature matrix (fill NA with median)\n",
    "X = df[feature_cols].fillna(df[feature_cols].median())\n",
    "\n",
    "# 5) run K‑Means (k = 3)\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# 6) pivot table: average Exam_Score + feature means, one row per cluster\n",
    "cluster_summary = (\n",
    "    df\n",
    "    .pivot_table(\n",
    "        index=\"Cluster\",\n",
    "        values=[target_col] + feature_cols,\n",
    "        aggfunc=\"mean\"\n",
    "    )\n",
    "    .round(2)\n",
    ")\n",
    "\n",
    "# 7) show results\n",
    "cluster_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1ff44e",
   "metadata": {},
   "source": [
    "**Chart Insight:**  \n",
    "The bar chart shows that **Cluster 1** outperforms the others with an average score of 68.8. Clusters 2 and 0 follow at 67.8 and 64.8, respectively.\n",
    "\n",
    "**Key Takeaways:**  \n",
    "- The cluster with the highest average exam score also had the highest attendance levels—reinforcing attendance as a critical success factor.  \n",
    "- Even though Cluster 2 had top previous scores, its lower attendance correlated with a slightly lower exam outcome, suggesting that consistent participation can outweigh past performance.  \n",
    "- Study hours and physical activity were nearly identical across clusters, indicating those alone aren’t enough to differentiate performance without strong attendance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8da734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "labels = cluster_summary.index.astype(str)\n",
    "scores = cluster_summary['Exam_Score']\n",
    "attendance = cluster_summary['Attendance']\n",
    "\n",
    "# Bar positions\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "# Plot exam scores\n",
    "bars1 = ax1.bar(x - width/2, scores, width, label='Avg Exam Score')\n",
    "ax1.set_xlabel('Cluster')\n",
    "ax1.set_ylabel('Avg Exam Score')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.legend(loc='upper left')\n",
    "\n",
    "# Plot attendance on twin axis\n",
    "ax2 = ax1.twinx()\n",
    "bars2 = ax2.bar(x + width/2, attendance, width, label='Avg Attendance (%)', alpha=0.7)\n",
    "ax2.set_ylabel('Avg Attendance (%)')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "plt.title('Avg Exam Score vs. Avg Attendance by Cluster')\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36d313d",
   "metadata": {},
   "source": [
    "**Insight from Pivot Table:**\n",
    "\n",
    "Students with higher attendance levels tend to have higher average exam scores, indicating a strong relationship between class participation and performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a3e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot table: average exam score by attendance level\n",
    "pivot_attendance = pd.pivot_table(df, \n",
    "                                  values='Exam_Score', \n",
    "                                  index='Attendance', \n",
    "                                  aggfunc='mean')\n",
    "pivot_attendance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a083a4",
   "metadata": {},
   "source": [
    "## Predictive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b602526",
   "metadata": {},
   "source": [
    "**Research Question:**\n",
    "Can a student’s exam score be predicted based on their **school behavior, family background, and school environment**?\n",
    "\n",
    "**Label:**\n",
    "* `Exam_Score`\n",
    "\n",
    "**Features:**\n",
    "* **School Behavior:** `Hours_Studied`, `Attendance`, `Sleep_Hours`, `Previous_Scored`, `Tutoring_Sessions`, `Physical_Activity`\n",
    "\n",
    "* **Family Background:** `Parental_Involvement`, `Family_Income`, `Parental_Education_Level`, `Learning_Disabilities`\n",
    "\n",
    "* **School Environment:** `Teacher_Quality`, `School_Type`, `Peer_Influence`, `Access_to_Resources`, `Motivation_Level`, `Internet_Access`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78229d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 1. Load the cleaned data\n",
    "df = pd.read_csv('cleaned_dataset.csv')\n",
    "\n",
    "# 2. Encode all categorical (object) columns\n",
    "df_enc = df.copy()\n",
    "encoders = {}\n",
    "for col in df_enc.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    df_enc[col] = le.fit_transform(df_enc[col])\n",
    "    encoders[col] = le\n",
    "\n",
    "# 3. Define features and label\n",
    "X = df_enc.drop(columns=['Exam_Score'])\n",
    "y = df_enc['Exam_Score']\n",
    "\n",
    "# 4. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 5. Cross-validation on training set\n",
    "lr = LinearRegression()\n",
    "cv_scores = cross_val_score(lr, X_train, y_train, cv=5, scoring='r2')\n",
    "print(\"CV R² scores:\", np.round(cv_scores, 3))\n",
    "print(\"Mean CV R²:  \", np.round(cv_scores.mean(), 3), \"\\n\")\n",
    "\n",
    "# 6. Fit on full training set and evaluate on test set\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2  = r2_score(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse:.2f}\")\n",
    "print(f\"Test R²:  {r2:.3f}\")\n",
    "\n",
    "# 7. Visualize actual vs. predicted\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.xlabel('Actual Exam Score')\n",
    "plt.ylabel('Predicted Exam Score')\n",
    "plt.title('Actual vs. Predicted Exam Scores')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d075deac",
   "metadata": {},
   "source": [
    "**Model Choice:** Linear Regression\n",
    "* Linear Regression was chosen because the features and outcomes can be directly understood through model coefficients.\n",
    "* `Exam_Score` is a continuous numeric value, which suits regression based methods well.\n",
    "* It is can be implemented quickly and efficiently. With this, it provides a good baseline model for performance before moving to more complex models.\n",
    "\n",
    "**Model Summary**\n",
    "* Mean Squared Error (MSE) ≈ **4.40**\n",
    "* R-Squared ≈ **0.69**\n",
    "\n",
    "**Interpretation of Summary**\n",
    "* The MSE of **√4.40 ≈ 2.1 points** shows that the model's exam score predictions are off by 2.1 points from the real exam scores. The exam scores range from 55 to 100 and with an error of approximately 2.1 points, which is relatively small, this shows that the model performs fairly well.\n",
    "* The R-squared value of **0.69** or **69%** shows that 69% of the variability in student's exam scores can be explained by the features provided (everything aside from the `Exam_Score`), but there is still 31% of variance that remains unexplained.\n",
    "\n",
    "**Analysis**\n",
    "* Based on these results, we can say that the **school behavior, family background, and school environment** components are relatively strong predictors of student exam scores. This can be seen from the model's fairly low error and high explained variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047a50ff",
   "metadata": {},
   "source": [
    "## Ethical Considerations\n",
    "\n",
    "- **Bias & fairness:**  \n",
    "  Attendance may correlate with socioeconomic factors (e.g., students from wealthier backgrounds might have fewer absences). Relying on this model could unfairly penalize disadvantaged students.\n",
    "\n",
    "- **Privacy:**  \n",
    "  Attendance records are personal data. Ensure anonymization if sharing or deploying any model.\n",
    "\n",
    "- **Societal impact:**  \n",
    "  If used to penalize low-attendance students, it could exacerbate existing inequalities.  \n",
    "  **Mitigation:** Use the model as a diagnostic tool (to identify at-risk students for support), not as a punitive measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdebe41",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Our multivariate linear regression model—incorporating school behavior, family background, and school environment—achieved:\n",
    "\n",
    "- **Mean Squared Error:** 4.40 (≈ 2.10 points RMSE)  \n",
    "- **R²:** 0.689 (≈ 69% of exam-score variance explained)\n",
    "\n",
    "These results show that, together, the chosen features provide a strong predictive signal: on average, predicted scores are within about 2 points of the true scores, and nearly 70% of the variability in performance is captured by our model.\n",
    "\n",
    "**Key Takeaways:**  \n",
    "- **School Behavior** factors (attendance, hours studied, previous scores) remain critical drivers of performance.  \n",
    "- **Family & Environment** variables (parental involvement, resources, teacher quality) also contribute meaningfully once combined in a single model.  \n",
    "\n",
    "**Limitations:**  \n",
    "- A linear model may not fully capture non-linear relationships or interactions among features.  \n",
    "- Roughly 31% of variability remains unexplained—potentially due to unmeasured factors (e.g., in-class engagement, test anxiety).\n",
    "\n",
    "**Future Directions:**  \n",
    "- Explore **non-linear**  methods (e.g., decision trees) to capture more complex interactions.   \n",
    "- Incorporate additional data (demographics, in-class metrics) to close the remaining performance gap and eliminate bias.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
